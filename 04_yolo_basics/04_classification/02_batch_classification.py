"""
æ‰¹é‡å›¾åƒåˆ†ç±»
==========

å­¦ä¹ ç›®æ ‡:
- æ‰¹é‡å¤„ç†å¤šå¼ å›¾åƒ
- åˆ†ç±»ç»“æœç»Ÿè®¡ä¸åˆ†æ
- ç»“æœå¯¼å‡º
"""

from pathlib import Path
import cv2
import numpy as np
import sys
import json
from collections import Counter

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent))
from utils.model_loader import load_yolo_model
from utils.image_loader import get_all_sample_images, IMAGES_DIR


def main():
    print("=" * 60)
    print("ğŸ“¦ æ‰¹é‡å›¾åƒåˆ†ç±»")
    print("=" * 60)
    
    # åŠ è½½åˆ†ç±»æ¨¡å‹
    model = load_yolo_model("yolo11n-cls.pt")
    
    # ==========================================
    # 1. è·å–æµ‹è¯•å›¾åƒ
    # ==========================================
    
    print("\nğŸ“· è·å–æµ‹è¯•å›¾åƒ...")
    
    # ä» datasets/images è·å–æ‰€æœ‰å›¾åƒ
    image_paths = get_all_sample_images()
    print(f"  å…± {len(image_paths)} å¼ å›¾åƒ")
    
    if len(image_paths) == 0:
        print("âš ï¸ æ²¡æœ‰å¯ç”¨çš„æµ‹è¯•å›¾åƒ")
        return
    
    # ==========================================
    # 2. æ‰¹é‡æ¨ç†
    # ==========================================
    
    print("\n" + "=" * 60)
    print("ğŸ” æ‰¹é‡åˆ†ç±»")
    print("=" * 60)
    
    # æ–¹æ³•1: ä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰å›¾åƒ
    results = model([str(p) for p in image_paths], verbose=False)
    
    # æ”¶é›†ç»“æœ
    classification_results = []
    
    for result in results:
        img_path = Path(result.path)
        top1_idx = result.probs.top1
        top1_conf = result.probs.top1conf.item()
        top1_name = result.names[top1_idx]
        
        # Top-3
        top3_idx = result.probs.top5[:3]
        top3_names = [result.names[idx] for idx in top3_idx]
        top3_confs = result.probs.top5conf[:3].tolist()
        
        classification_results.append({
            "filename": img_path.name,
            "predicted_class": top1_name,
            "confidence": top1_conf,
            "top3": list(zip(top3_names, top3_confs))
        })
        
        print(f"  {img_path.name}: {top1_name} ({top1_conf:.2%})")
    
    # ==========================================
    # 3. ç»“æœç»Ÿè®¡åˆ†æ
    # ==========================================
    
    print("\n" + "=" * 60)
    print("ğŸ“Š ç»Ÿè®¡åˆ†æ")
    print("=" * 60)
    
    # ç±»åˆ«åˆ†å¸ƒ
    class_counter = Counter([r["predicted_class"] for r in classification_results])
    
    print("\n  ç±»åˆ«åˆ†å¸ƒ:")
    for cls, count in class_counter.most_common(10):
        bar = "â–ˆ" * count
        print(f"    {cls:20s}: {count:3d} {bar}")
    
    # ç½®ä¿¡åº¦ç»Ÿè®¡
    confidences = [r["confidence"] for r in classification_results]
    print(f"\n  ç½®ä¿¡åº¦ç»Ÿè®¡:")
    print(f"    å¹³å‡ç½®ä¿¡åº¦: {np.mean(confidences):.2%}")
    print(f"    æœ€é«˜ç½®ä¿¡åº¦: {np.max(confidences):.2%}")
    print(f"    æœ€ä½ç½®ä¿¡åº¦: {np.min(confidences):.2%}")
    
    if len(confidences) > 1:
        print(f"    æ ‡å‡†å·®: {np.std(confidences):.2%}")
    
    # ç½®ä¿¡åº¦åˆ†å¸ƒ
    high_conf = sum(1 for c in confidences if c > 0.8)
    medium_conf = sum(1 for c in confidences if 0.5 <= c <= 0.8)
    low_conf = sum(1 for c in confidences if c < 0.5)
    
    print(f"\n  ç½®ä¿¡åº¦åˆ†å¸ƒ:")
    print(f"    é«˜ (>80%): {high_conf} å¼ ")
    print(f"    ä¸­ (50-80%): {medium_conf} å¼ ")
    print(f"    ä½ (<50%): {low_conf} å¼ ")
    
    # ==========================================
    # 4. æŒ‰ç½®ä¿¡åº¦ç­›é€‰
    # ==========================================
    
    print("\n" + "=" * 60)
    print("ğŸ” ç½®ä¿¡åº¦ç­›é€‰")
    print("=" * 60)
    
    threshold = 0.3
    high_conf_results = [r for r in classification_results if r["confidence"] > threshold]
    print(f"\n  ç½®ä¿¡åº¦ > {threshold:.0%} çš„ç»“æœ: {len(high_conf_results)}/{len(classification_results)}")
    
    for r in high_conf_results[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
        print(f"    {r['filename']}: {r['predicted_class']} ({r['confidence']:.2%})")
    
    # ==========================================
    # 5. ç»“æœå¯¼å‡º
    # ==========================================
    
    print("\n" + "=" * 60)
    print("ğŸ’¾ å¯¼å‡ºç»“æœ")
    print("=" * 60)
    
    output_dir = Path(__file__).parent / "outputs"
    output_dir.mkdir(exist_ok=True)
    
    # å¯¼å‡º JSON
    json_results = []
    for r in classification_results:
        json_results.append({
            "filename": r["filename"],
            "predicted_class": r["predicted_class"],
            "confidence": round(r["confidence"], 4),
            "top3": [(name, round(conf, 4)) for name, conf in r["top3"]]
        })
    
    json_path = output_dir / "classification_results.json"
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(json_results, f, indent=2, ensure_ascii=False)
    print(f"  JSON ç»“æœ: {json_path}")
    
    # å¯¼å‡º CSV
    csv_path = output_dir / "classification_results.csv"
    with open(csv_path, "w", encoding="utf-8") as f:
        f.write("filename,predicted_class,confidence\n")
        for r in classification_results:
            f.write(f"{r['filename']},{r['predicted_class']},{r['confidence']:.4f}\n")
    print(f"  CSV ç»“æœ: {csv_path}")
    
    # ==========================================
    # 6. åˆ›å»ºç»“æœæ‘˜è¦å›¾
    # ==========================================
    
    if len(classification_results) > 0:
        print("\n  åˆ›å»ºç»“æœæ‘˜è¦å›¾...")
        create_summary_image(classification_results, output_dir, IMAGES_DIR)
    
    print("\nâœ… æ‰¹é‡åˆ†ç±»æ¼”ç¤ºå®Œæˆ!")


def create_summary_image(results, output_dir: Path, images_dir: Path):
    """åˆ›å»ºç»“æœæ‘˜è¦é©¬èµ›å…‹å›¾"""
    # æ¯è¡Œæ˜¾ç¤º5å¼ å›¾
    cols = min(5, len(results))
    rows = (len(results) + cols - 1) // cols
    
    thumb_size = 120
    padding = 5
    text_height = 40
    
    total_width = cols * (thumb_size + padding) + padding
    total_height = rows * (thumb_size + text_height + padding) + padding
    
    summary = np.full((total_height, total_width, 3), 255, dtype=np.uint8)
    
    for i, result in enumerate(results):
        row = i // cols
        col = i % cols
        
        x = col * (thumb_size + padding) + padding
        y = row * (thumb_size + text_height + padding) + padding
        
        # åŠ è½½å¹¶ç¼©æ”¾å›¾åƒ
        img_path = images_dir / result["filename"]
        if img_path.exists():
            img = cv2.imread(str(img_path))
            if img is not None:
                img_resized = cv2.resize(img, (thumb_size, thumb_size))
                summary[y:y+thumb_size, x:x+thumb_size] = img_resized
        
        # æ·»åŠ æ–‡å­—
        text = f"{result['predicted_class'][:12]}"
        conf_text = f"{result['confidence']:.0%}"
        
        cv2.putText(summary, text, (x, y + thumb_size + 15),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 0), 1)
        cv2.putText(summary, conf_text, (x, y + thumb_size + 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 128, 0), 1)
    
    cv2.imwrite(str(output_dir / "batch_summary.jpg"), summary)
    print(f"  æ‘˜è¦å›¾: {output_dir / 'batch_summary.jpg'}")


if __name__ == "__main__":
    main()
