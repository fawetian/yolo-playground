"""
OpenCV ä¸ YOLO åŸºç¡€é›†æˆ
=====================

å­¦ä¹ ç›®æ ‡:
- ç†è§£ OpenCV å›¾åƒè¯»å–ä¸ YOLO æ¨ç†çš„ç»“åˆ
- æ‰‹åŠ¨è§£æ YOLO ç»“æœ (Results å¯¹è±¡)
- ä½¿ç”¨ OpenCV åŸç”Ÿç»˜å›¾å‡½æ•°ç»˜åˆ¶æ£€æµ‹æ¡†å’Œæ ‡ç­¾
"""

from pathlib import Path
import cv2
import numpy as np
import sys
import random

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent))
from utils.model_loader import load_yolo_model
from utils.image_loader import get_sample_image


def main():
    print("=" * 60)
    print("ğŸ”„ OpenCV + YOLO åŸºç¡€é›†æˆ")
    print("=" * 60)
    
    # 1. åŠ è½½æ¨¡å‹
    model = load_yolo_model("yolo11n.pt")
    
    # 2. è¯»å–å›¾åƒ (ä½¿ç”¨ OpenCV)
    # è·å–æµ‹è¯•å›¾åƒè·¯å¾„
    img_path = get_sample_image("bus.jpg")
    print(f"\nğŸ“· è¯»å–å›¾åƒ: {img_path}")
    
    # cv2.imread è¯»å–ä¸º BGR æ ¼å¼
    frame = cv2.imread(str(img_path))
    if frame is None:
        print("âŒ æ— æ³•è¯»å–å›¾åƒ")
        return

    # 3. æ‰§è¡Œæ¨ç†
    print("ğŸ” æ‰§è¡Œæ¨ç†...")
    # YOLOv8+ å¯ä»¥ç›´æ¥æ¥å— BGR numpy array
    results = model(frame, verbose=False)
    result = results[0]
    
    # 4. æ‰‹åŠ¨ç»˜åˆ¶ç»“æœ
    # ç›¸æ¯” result.plot()ï¼Œæ‰‹åŠ¨ç»˜åˆ¶ç»™æˆ‘ä»¬æ›´å¤šæ§åˆ¶æƒ (æ ·å¼ã€é¢œè‰²ã€é€»è¾‘)
    print("ğŸ¨ ç»˜åˆ¶æ£€æµ‹ç»“æœ...")
    
    annotated_frame = frame.copy()
    
    boxes = result.boxes
    print(f"  æ£€æµ‹åˆ° {len(boxes)} ä¸ªç›®æ ‡")
    
    for box in boxes:
        # è·å–åæ ‡ (xyxy)
        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)
        
        # è·å–ç±»åˆ«å’Œç½®ä¿¡åº¦
        cls_id = int(box.cls[0].item())
        conf = float(box.conf[0].item())
        class_name = result.names[cls_id]
        
        # ä»…ç»˜åˆ¶ç½®ä¿¡åº¦ > 0.5 çš„ç›®æ ‡
        if conf > 0.5:
            # ç”Ÿæˆéšæœºé¢œè‰² (åŸºäºç±»åˆ«ID)
            random.seed(cls_id)
            color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))
            
            # 1. ç”»çŸ©å½¢æ¡†
            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)
            
            # 2. å‡†å¤‡æ ‡ç­¾æ–‡å­—
            label = f"{class_name} {conf:.2f}"
            
            # 3. è®¡ç®—æ–‡å­—èƒŒæ™¯å°ºå¯¸
            (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)
            
            # 4. ç”»æ–‡å­—èƒŒæ™¯ (å¡«å……çŸ©å½¢)
            cv2.rectangle(annotated_frame, (x1, y1 - 20), (x1 + w, y1), color, -1)
            
            # 5. ç”»ç™½è‰²æ–‡å­—
            text_color = (255, 255, 255)
            cv2.putText(annotated_frame, label, (x1, y1 - 5),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, text_color, 1)
            
            print(f"    - {class_name}: {conf:.2%}")
            
    # 5. ä¿å­˜ç»“æœ
    output_dir = Path(__file__).parent / "outputs"
    output_dir.mkdir(exist_ok=True)
    output_path = output_dir / "cv2_integration_result.jpg"
    
    cv2.imwrite(str(output_path), annotated_frame)
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜: {output_path}")
    
    # æ³¨æ„: åœ¨æœåŠ¡å™¨/æ— å¤´ç¯å¢ƒä¸­ä¸è¦ä½¿ç”¨ cv2.imshow
    # cv2.imshow("Result", annotated_frame)
    # cv2.waitKey(0)
    # cv2.destroyAllWindows()


if __name__ == "__main__":
    main()
