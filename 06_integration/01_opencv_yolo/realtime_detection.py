"""
OpenCV + YOLO å®æ—¶æ£€æµ‹ (macOS ç‰ˆ)
==============================

å­¦ä¹ ç›®æ ‡:
- ç»“åˆ OpenCV è§†é¢‘æ•è·å’Œ YOLO æ£€æµ‹
- å®ç°å®æ—¶ç›®æ ‡æ£€æµ‹
- è‡ªå®šä¹‰å¯è§†åŒ–æ•ˆæœ

macOS è¯´æ˜:
- é¦–æ¬¡è¿è¡Œä¼šè¯·æ±‚æ‘„åƒå¤´æƒé™
- Apple Silicon ä½¿ç”¨ MPS åŠ é€Ÿ
"""

import cv2
import numpy as np
from ultralytics import YOLO
import torch
import time


def get_device():
    """è·å–æœ€ä½³å¯ç”¨è®¾å¤‡ (macOS ä¼˜åŒ–)"""
    if torch.backends.mps.is_available():
        return "mps"
    elif torch.cuda.is_available():
        return "0"
    else:
        return "cpu"


def main():
    print("=" * 60)
    print("ğŸ¥ å®æ—¶ç›®æ ‡æ£€æµ‹ (macOS)")
    print("=" * 60)
    
    # æ£€æµ‹è®¾å¤‡
    device = get_device()
    device_names = {"mps": "Apple Silicon GPU", "cpu": "CPU", "0": "NVIDIA GPU"}
    print(f"ğŸ’» ä½¿ç”¨è®¾å¤‡: {device_names.get(device, device)}")
    
    # åŠ è½½æ¨¡å‹ (é€‰æ‹©è¾ƒå°çš„æ¨¡å‹ä»¥ä¿è¯é€Ÿåº¦)
    model = YOLO("yolo11n.pt")
    
    # ==========================================
    # 1. åˆå§‹åŒ–è§†é¢‘æ•è·
    # ==========================================
    
    # ä½¿ç”¨æ‘„åƒå¤´
    # macOS: é¦–æ¬¡è¿è¡Œä¼šè¯·æ±‚æ‘„åƒå¤´æƒé™ï¼Œè¯·ç‚¹å‡»"å…è®¸"
    print("\nğŸ“· æ­£åœ¨è®¿é—®æ‘„åƒå¤´...")
    print("   å¦‚æœå¼¹å‡ºæƒé™è¯·æ±‚ï¼Œè¯·ç‚¹å‡»'å…è®¸'")
    
    cap = cv2.VideoCapture(0)
    
    # å¦‚æœæ²¡æœ‰æ‘„åƒå¤´ï¼Œä½¿ç”¨è§†é¢‘æ–‡ä»¶
    # cap = cv2.VideoCapture("path/to/video.mp4")
    
    if not cap.isOpened():
        print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
        print("ğŸ’¡ macOS æç¤º:")
        print("   1. ç¡®ä¿å·²æˆäºˆæ‘„åƒå¤´æƒé™")
        print("   2. ç³»ç»Ÿè®¾ç½® â†’ éšç§ä¸å®‰å…¨æ€§ â†’ æ‘„åƒå¤´ â†’ å¼€å¯ Terminal/IDE")
        print("   3. æˆ–ä¿®æ”¹ä»£ç ä½¿ç”¨è§†é¢‘æ–‡ä»¶")
        return
    
    # è®¾ç½®åˆ†è¾¨ç‡ (é™ä½åˆ†è¾¨ç‡å¯æé«˜å¸§ç‡)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    
    print("âœ… æ‘„åƒå¤´å·²æ‰“å¼€")
    
    # ==========================================
    # 2. ä¸»å¾ªç¯
    # ==========================================
    
    print("\nğŸ¬ æŒ‰ 'q' é€€å‡º")
    print("   æŒ‰ 's' æˆªå›¾")
    print("   æŒ‰ 'p' æš‚åœ/ç»§ç»­")
    
    paused = False
    frame_count = 0
    fps_start_time = time.time()
    fps = 0
    
    while True:
        if not paused:
            ret, frame = cap.read()
            if not ret:
                print("âŒ æ— æ³•è¯»å–å¸§")
                break
            
            # è¿è¡Œ YOLO æ£€æµ‹ (ä½¿ç”¨æœ€ä½³è®¾å¤‡)
            results = model(frame, verbose=False, device=device)
            result = results[0]
            
            # ==========================================
            # 3. è‡ªå®šä¹‰å¯è§†åŒ–
            # ==========================================
            
            annotated_frame = custom_visualization(frame, result, model.names)
            
            # è®¡ç®— FPS
            frame_count += 1
            if frame_count % 30 == 0:
                fps = 30 / (time.time() - fps_start_time)
                fps_start_time = time.time()
            
            # æ˜¾ç¤º FPS
            cv2.putText(
                annotated_frame, 
                f"FPS: {fps:.1f}", 
                (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX, 
                1, (0, 255, 0), 2
            )
            
            # æ˜¾ç¤ºæ£€æµ‹æ•°é‡
            num_detections = len(result.boxes)
            cv2.putText(
                annotated_frame, 
                f"Detections: {num_detections}", 
                (10, 70),
                cv2.FONT_HERSHEY_SIMPLEX, 
                1, (0, 255, 0), 2
            )
        
        # macOS: ä½¿ç”¨ WINDOW_NORMAL å¯ä»¥è°ƒæ•´çª—å£å¤§å°
        cv2.namedWindow("YOLO Realtime Detection", cv2.WINDOW_NORMAL)
        cv2.imshow("YOLO Realtime Detection", annotated_frame)
        
        # ==========================================
        # 4. é”®ç›˜æ§åˆ¶
        # ==========================================
        
        key = cv2.waitKey(1) & 0xFF
        
        if key == ord('q'):
            break
        elif key == ord('s'):
            # æˆªå›¾
            screenshot_path = f"screenshot_{int(time.time())}.jpg"
            cv2.imwrite(screenshot_path, annotated_frame)
            print(f"ğŸ“¸ æˆªå›¾ä¿å­˜: {screenshot_path}")
        elif key == ord('p'):
            paused = not paused
            print("â¸ï¸ æš‚åœ" if paused else "â–¶ï¸ ç»§ç»­")
    
    # æ¸…ç†
    cap.release()
    cv2.destroyAllWindows()
    cv2.waitKey(1)  # macOS éœ€è¦é¢å¤–çš„ waitKey æ¥å®Œå…¨å…³é—­çª—å£
    print("\nğŸ‘‹ æ£€æµ‹ç»“æŸ")


def custom_visualization(frame: np.ndarray, result, class_names: dict) -> np.ndarray:
    """
    è‡ªå®šä¹‰å¯è§†åŒ–æ•ˆæœ
    
    Args:
        frame: åŸå§‹å¸§
        result: YOLO æ£€æµ‹ç»“æœ
        class_names: ç±»åˆ«åç§°å­—å…¸
    
    Returns:
        å¸¦æ ‡æ³¨çš„å¸§
    """
    annotated = frame.copy()
    boxes = result.boxes
    
    # ä¸ºä¸åŒç±»åˆ«å®šä¹‰é¢œè‰²
    colors = {
        0: (0, 255, 0),     # person - ç»¿è‰²
        2: (255, 0, 0),     # car - è“è‰²
        5: (0, 0, 255),     # bus - çº¢è‰²
        7: (255, 255, 0),   # truck - é’è‰²
    }
    default_color = (128, 128, 128)
    
    for box in boxes:
        # è·å–ä¿¡æ¯
        x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
        conf = box.conf[0].item()
        cls_id = int(box.cls[0].item())
        cls_name = class_names[cls_id]
        
        # é€‰æ‹©é¢œè‰²
        color = colors.get(cls_id, default_color)
        
        # ç»˜åˆ¶è¾¹ç•Œæ¡†
        cv2.rectangle(annotated, (x1, y1), (x2, y2), color, 2)
        
        # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
        label = f"{cls_name} {conf:.0%}"
        (label_w, label_h), baseline = cv2.getTextSize(
            label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1
        )
        
        cv2.rectangle(
            annotated, 
            (x1, y1 - label_h - 10), 
            (x1 + label_w + 4, y1), 
            color, -1
        )
        
        # ç»˜åˆ¶æ ‡ç­¾æ–‡å­—
        cv2.putText(
            annotated, label, 
            (x1 + 2, y1 - 5),
            cv2.FONT_HERSHEY_SIMPLEX, 
            0.6, (255, 255, 255), 1
        )
        
        # å¯é€‰: ç»˜åˆ¶ä¸­å¿ƒç‚¹
        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2
        cv2.circle(annotated, (cx, cy), 4, color, -1)
    
    return annotated


if __name__ == "__main__":
    main()

